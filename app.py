# app.py
import streamlit as st
import torch, random, time, traceback
from PIL import Image, ImageFilter
from io import BytesIO

# --- ëª¨ë“ˆí™”ëœ íŒŒì¼ì—ì„œ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸° ---
from config import CONFIG
from ui import setup_sidebar, display_results, clear_results
from model_loader import load_pipeline, load_anime_segmenter, load_mediapipe_segmenter
from image_processing import (
    preprocess_control_images,
    segment_anime_image,
    composite_with_background,
    segment_person_with_mediapipe,
    calculate_composition_geometry,
)
from utils import (
    get_stage_weights,
    update_progress_bar,
    complete_progress_bar,
    get_new_dimensions,
)

try:
    from lottie_utils import show_lottie_animation

    LOTTIE_AVAILABLE = True
except ImportError:
    LOTTIE_AVAILABLE = False

# ---------- 1. í˜ì´ì§€ ë° ì„¸ì…˜ ìƒíƒœ ì„¤ì • ----------
st.set_page_config(layout="wide", page_title="AI Image Generator")
st.title("ğŸ¨ AI í•„í„° ìŠ¤íŠœë””ì˜¤")
with st.expander("ğŸ¤” ì‚¬ìš© ê°€ì´ë“œ (í´ë¦­í•˜ì—¬ í¼ì³ë³´ì„¸ìš”!)", expanded=True):
    st.markdown(
        """
        **AI í•„í„° ìŠ¤íŠœë””ì˜¤ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ê°„ë‹¨í•œ ë‹¨ê³„ë¡œ ì—¬ëŸ¬ë¶„ì˜ ì‚¬ì§„ì„ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ë°”ê¿”ë³´ì„¸ìš”.**

        1.  **ğŸ¨ í•„í„° ì„ íƒ:** ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë§ˆìŒì— ë“œëŠ” AI í•„í„° (ì˜ˆ: ì§€ë¸Œë¦¬, í”½ì‚¬ ìŠ¤íƒ€ì¼)ë¥¼ ì„ íƒí•˜ì„¸ìš”.
        2.  **ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ:** ë³€í™˜í•˜ê³  ì‹¶ì€ **ì¸ë¬¼ ì‚¬ì§„**ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤. ì–¼êµ´ê³¼ ì „ì‹ ì´ ì˜ ë³´ì¼ìˆ˜ë¡ ê²°ê³¼ê°€ ì¢‹ìŠµë‹ˆë‹¤.
        3.  **âœ¨ í•©ì„± ëª¨ë“œ (ì„ íƒ ì‚¬í•­):**
            * **`ì‚¬ìš© ì•ˆ í•¨`**: ì—…ë¡œë“œí•œ ì‚¬ì§„ êµ¬ë„ ê·¸ëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ AI í•„í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            * **`ë°°ê²½ìœ¼ë¡œ í•©ì„±`**: AIê°€ ìƒì„±í•œ ìºë¦­í„°ë§Œ ë¶„ë¦¬í•˜ì—¬, ë¯¸ë¦¬ ì¤€ë¹„ëœ ë©‹ì§„ ë°°ê²½ê³¼ í•©ì³ì¤ë‹ˆë‹¤.
        4.  **ğŸš€ ìƒì„± ì‹œì‘:** ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´ **'ì´ë¯¸ì§€ ìƒì„± ì‹œì‘!'** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”! ì ì‹œ ê¸°ë‹¤ë¦¬ë©´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤.
        5.  **ğŸ’¾ ì €ì¥ ë° ê³µìœ :** ì™„ì„±ëœ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¹œêµ¬ë“¤ê³¼ ê³µìœ í•´ë³´ì„¸ìš”!
        """
    )
st.markdown("---")

if "generation_in_progress" not in st.session_state:
    st.session_state.generation_in_progress = False
if "current_filter" not in st.session_state:
    st.session_state.current_filter = list(CONFIG["filters"].keys())[0]
if "current_mode" not in st.session_state:
    st.session_state.current_mode = "ì‚¬ìš© ì•ˆ í•¨"

# ---------- 2. UI ë° ëª¨ë¸ ë¡œë”© ----------
ui = setup_sidebar()
lottie_placeholder = st.empty()

# 1. í•„í„°ê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œ: ëª¨ë¸ ì „ì²´ë¥¼ ìƒˆë¡œ ë¡œë“œí•´ì•¼ í•˜ë¯€ë¡œ ìºì‹œë¥¼ ë¹„ì›ë‹ˆë‹¤.
if st.session_state.current_filter != ui["filter_name"]:
    st.toast(
        f"í•„í„°ë¥¼ '{ui['filter_name']}'(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. ëª¨ë¸ì„ ìƒˆë¡œ ë¡œë“œí•©ë‹ˆë‹¤..."
    )
    st.session_state.current_filter = ui["filter_name"]
    st.cache_resource.clear()  # ì „ì²´ ìºì‹œ ì‚­ì œ
    clear_results()

# 2. í•©ì„± ëª¨ë“œê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œ: ì´ì „ ê²°ê³¼ë§Œ ì§€ìš°ê³ , ëª¨ë¸ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
if st.session_state.current_mode != ui["mode"]:
    st.toast(f"í•©ì„± ëª¨ë“œë¥¼ '{ui['mode']}'(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
    st.session_state.current_mode = ui["mode"]
    clear_results()
    st.rerun()

# ëª¨ë¸ ë¡œë”©
try:
    if LOTTIE_AVAILABLE:
        with lottie_placeholder:
            show_lottie_animation(
                filepath="Man and robot.json", height=300, key="rocket"
            )

    t0 = time.perf_counter()
    pipe, annotators, lora_status, device = load_pipeline(ui["filter_config"])
    anime_segmenter = (
        load_anime_segmenter(device) if ui["mode"] == "ë°°ê²½ìœ¼ë¡œ í•©ì„±" else None
    )
    mediapipe_segmenter = (
        load_mediapipe_segmenter() if ui["mode"] == "ë°°ê²½ìœ¼ë¡œ í•©ì„±" else None
    )
    t1 = time.perf_counter()

    lottie_placeholder.empty()
    st.sidebar.success(f"**ëª¨ë¸ ë¡œë”© ì™„ë£Œ!** ({t1 - t0:.2f}ì´ˆ)")

except Exception as e:
    lottie_placeholder.empty()
    st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨\n\n{e}")
    st.stop()


# ---------- 3. ë©”ì¸ ë¡œì§ ----------

# 3-A. ì‹œì‘ ì „ í™”ë©´
if (
    not st.session_state.get("generation_in_progress")
    and "result_image" not in st.session_state
):
    if ui["uploaded_file"]:
        input_original = Image.open(ui["uploaded_file"]).convert("RGB")
        st.subheader("ğŸ–¼ï¸ ì—…ë¡œë“œëœ ì›ë³¸ ì´ë¯¸ì§€")
        c1, c2, c3 = st.columns([1, 2, 1])
        with c2:
            st.image(input_original, use_container_width=True)
        st.info(
            "ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ 'ì´ë¯¸ì§€ ìƒì„± ì‹œì‘!' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
        )
    else:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì¸ë¬¼ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# 3-B. ìƒì„± í”„ë¡œì„¸ìŠ¤
elif st.session_state.get("generation_in_progress"):
    try:
        # --- ì´ˆê¸°í™” ---
        st.subheader("âœ¨ ìƒì„± ì¤‘...")
        c1, c2, c3 = st.columns([1, 2, 1])
        with c2:
            placeholder = st.empty()
        progress_bar = st.progress(0, text="ëŒ€ê¸° ì¤‘...")
        stage_weights = get_stage_weights(ui["mode"])
        completed_stages = []

        # --- ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ì¤€ë¹„ ---
        input_original = Image.open(st.session_state.uploaded_file).convert("RGB")
        nw, nh = get_new_dimensions(input_original.size)
        input_for_generation = input_original.resize((nw, nh), Image.Resampling.LANCZOS)

        if ui["mode"] == "ë°°ê²½ìœ¼ë¡œ í•©ì„±" and ui["bg_path"] and mediapipe_segmenter:
            bg_img = Image.open(ui["bg_path"]).convert("RGB")
            segmented_person = segment_person_with_mediapipe(
                mediapipe_segmenter, input_original
            )
            geom = calculate_composition_geometry(segmented_person.size, bg_img.size)
            person_resized = segmented_person.resize(
                geom["size"], Image.Resampling.LANCZOS
            )
            composite_preview = bg_img.copy()
            composite_preview.paste(person_resized, geom["pos"], person_resized)
            blurred_preview = composite_preview.filter(
                ImageFilter.GaussianBlur(radius=20)
            )
        else:
            blurred_preview = input_for_generation.filter(
                ImageFilter.GaussianBlur(radius=20)
            )
        placeholder.image(
            blurred_preview, caption="ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...", use_container_width=True
        )

        t_start = time.perf_counter()

        # --- 1. ControlNet ---
        update_progress_bar(
            progress_bar, "controlnet", 0.0, stage_weights, completed_stages
        )
        control_imgs = preprocess_control_images(annotators, input_for_generation)
        update_progress_bar(
            progress_bar, "controlnet", 1.0, stage_weights, completed_stages
        )
        completed_stages.append("controlnet")

        # --- 2. AI ì´ë¯¸ì§€ ìƒì„± ---
        adv = ui["filter_config"]["advanced_settings"]
        seed = random.randint(0, 2**32 - 1)
        actual_steps = int(adv["steps"] * adv["denoising"])

        def progress_bar_callback(pipe, step_index, timestep, callback_kwargs):
            frac = (step_index + 1) / actual_steps
            current_progress = update_progress_bar(
                progress_bar, "generation", frac, stage_weights, completed_stages
            )
            progress_bar.progress(
                int(current_progress * 100),
                text=f"AI ìƒì„± ì¤‘... (ìŠ¤í… {step_index + 1}/{actual_steps})",
            )
            return callback_kwargs

        generated_image = pipe(
            prompt=ui["filter_config"]["trigger"],
            negative_prompt=ui["filter_config"]["negative"],
            image=input_for_generation,
            height=nh,
            width=nw,
            control_image=list(control_imgs.values()),
            num_inference_steps=adv["steps"],
            guidance_scale=adv["cfg"],
            strength=adv["denoising"],
            cross_attention_kwargs={"scale": adv["lora_weight"]},
            controlnet_conditioning_scale=[adv["pose_scale"], adv["canny_scale"]],
            generator=torch.Generator(device=device).manual_seed(seed),
            callback_on_step_end=progress_bar_callback,
        ).images[0]
        completed_stages.append("generation")

        # --- 3. ë°°ê²½ í•©ì„± ---
        final_result = generated_image
        character_rgba = None
        if ui["mode"] == "ë°°ê²½ìœ¼ë¡œ í•©ì„±":
            update_progress_bar(
                progress_bar, "background_process", 0.0, stage_weights, completed_stages
            )
            character_rgba = segment_anime_image(
                anime_segmenter, generated_image, device
            )
            if ui["bg_path"]:
                final_result = composite_with_background(character_rgba, ui["bg_path"])
            else:
                st.warning(
                    "ë°°ê²½ì´ ì„ íƒë˜ì§€ ì•Šì•„ íˆ¬ëª… ë°°ê²½ì˜ ìºë¦­í„° ì´ë¯¸ì§€ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."
                )
                final_result = character_rgba
            completed_stages.append("background_process")

        # --- 4. í˜ì´ë“œì¸ ---
        if final_result.size != blurred_preview.size:
            blurred_preview = blurred_preview.resize(
                final_result.size, Image.Resampling.LANCZOS
            )

        final_rgb = final_result.convert("RGB")  # ë¸”ë Œë”©ì„ ìœ„í•´ RGBë¡œ ë³€í™˜
        for i in range(16):
            alpha = i / 15
            frame = Image.blend(blurred_preview, final_rgb, alpha)
            placeholder.image(frame, use_container_width=True)
            update_progress_bar(
                progress_bar, "fade", alpha, stage_weights, completed_stages
            )
            time.sleep(0.03)

        # --- 5. ìµœì¢… ì •ë¦¬ ---
        placeholder.image(final_result, use_container_width=True)
        complete_progress_bar(progress_bar)
        time.sleep(0.2)
        progress_bar.empty()

        st.session_state.result_image = final_result
        st.session_state.character_rgba = character_rgba
        st.session_state.last_generation_time = time.perf_counter() - t_start
        st.session_state.used_seed = seed

    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
    finally:
        st.session_state.generation_in_progress = False
        st.rerun()

# 3-C. ê²°ê³¼ í‘œì‹œ
elif "result_image" in st.session_state:
    display_results(ui)
